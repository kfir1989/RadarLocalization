{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "directory = r\"/home/kfir/workspace/nuScenes/v1.0-trainval\"\n",
    "nusc = NuScenes(version=\"v1.0-trainval\", dataroot=directory, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6997a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from simulation import NuscenesSimulation\n",
    "\n",
    "class DummyModel():\n",
    "    def __init__(self):\n",
    "        self.mm = True\n",
    "        \n",
    "scene = 690\n",
    "dummy_model = DummyModel()\n",
    "video_list={'video' : False, 'video_debug': False, 'video_pf': False, 'video_pf_xy': False, 'dynamic_tracker': False}\n",
    "sim = NuscenesSimulation(nusc=nusc, model=dummy_model, scene_id=scene, Nmax=1200, video_list=video_list, save_processed=True)\n",
    "\n",
    "#data = NuscenesProcessedDatabase(scene_id=scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points\n",
    "\n",
    "def projectRadarOnCamera(nusc, pc, im, cs_record, min_dist: float = 1.0):\n",
    "\n",
    "    pc.translate(-np.array(cs_record['translation']))\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix.T)\n",
    "\n",
    "    # Fifth step: actually take a \"picture\" of the point cloud.\n",
    "    # Grab the depths (camera frame z axis points away from the camera).\n",
    "    depths = pc.points[2, :]\n",
    "\n",
    "    # Retrieve the color from the depth.\n",
    "    coloring = depths\n",
    "\n",
    "    # Take the actual picture (matrix multiplication with camera-matrix + renormalization).\n",
    "    points = view_points(pc.points[:3, :], np.array(cs_record['camera_intrinsic']), normalize=True)\n",
    "\n",
    "    # Remove points that are either outside or behind the camera. Leave a margin of 1 pixel for aesthetic reasons.\n",
    "    # Also make sure points are at least 1m in front of the camera to avoid seeing the lidar points on the camera\n",
    "    # casing for non-keyframes which are slightly out of sync.\n",
    "    mask = np.ones(depths.shape[0], dtype=bool)\n",
    "    mask = np.logical_and(mask, depths > min_dist)\n",
    "    mask = np.logical_and(mask, points[0, :] > 1)\n",
    "    mask = np.logical_and(mask, points[0, :] < im.shape[0] - 1)\n",
    "    mask = np.logical_and(mask, points[1, :] > 1)\n",
    "    mask = np.logical_and(mask, points[1, :] < im.shape[1] - 1)\n",
    "    points = points[:, mask]\n",
    "    coloring = coloring[mask]\n",
    "\n",
    "    return points, coloring, im\n",
    "\n",
    "nusc_map = sim.dataset.nusc_map\n",
    "video_with_priors = True\n",
    "\n",
    "t = 500\n",
    "img = sim.dataset.getSyncedImage(t)\n",
    "zw, covw, prior, dw, video_data, nusc_map = sim.dataset.getData(t, GT=True)\n",
    "pc = sim.dataset.getEGORadarData(t, video_data[\"pos\"], video_data[\"rot_gt\"])\n",
    "\n",
    "points, coloring, im = projectRadarOnCamera(nusc, pc, img, sim.dataset.cs_record_camera)\n",
    "#video_data, polynoms, points, dynamic_tracks, dynamic_clusters, mm_results, translation, debug_info = data.load(t)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 32))\n",
    "ax.imshow(im)\n",
    "print(points.shape)\n",
    "ax.scatter(points[0, :], points[1, :], c=coloring, s=30)\n",
    "ax.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
